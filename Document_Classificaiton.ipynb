{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cnLdAX7F6-DZWlenXvfjzoTBSJmei02B",
      "authorship_tag": "ABX9TyPlzfXPO7sAoJPEBEm1xomv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinaus/ML/blob/main/Document_Classificaiton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Nt9UWLLRS3i"
      },
      "outputs": [],
      "source": [
        "%pip install azure-ai-formrecognizer openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Parse document using Azure Document Intelligence\n",
        "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from openai import OpenAI\n",
        "\n",
        "# Replace with your actual access token\n",
        "from google.colab import userdata\n",
        "DOCUMENTINTEL_KEY = userdata.get('DOCUMENTINTEL_KEY')\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/ML/Training\"\n",
        "all_entries = os.listdir(directory_path)\n",
        "\n",
        "\n",
        "# Azure Document Intelligence setup\n",
        "endpoint = \"https://documentsclassifier.cognitiveservices.azure.com/\"\n",
        "key = DOCUMENTINTEL_KEY\n",
        "\n",
        "document_analysis_client = DocumentAnalysisClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(DOCUMENTINTEL_KEY)\n",
        ")\n",
        "\n",
        "classification_results = {}\n",
        "\n",
        "# Process only the top 2 files\n",
        "for file_name in document_files:\n",
        "    if file_name.lower().endswith('.odt'):\n",
        "        print(f\"Skipping .odt file: {file_name}\")\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(directory_path, file_name)\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            poller = document_analysis_client.begin_analyze_document(\"prebuilt-document\", f)\n",
        "            result = poller.result()\n",
        "\n",
        "            # Extract content\n",
        "            extracted_content = result.content\n",
        "\n",
        "            # Step 2: Send content to GPT for classification\n",
        "            client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Classify the following document text into an appropriate category.\n",
        "            Also return the number of pages.\n",
        "            include the precide page number where the 'Financial and Operational Results for the Year Ended December 31, 2023' is included in the document.\n",
        "            If the above exists in more than one page have it displayed as comma separated like 1,2\n",
        "            Return JSON with fields: file name, category, confidence, description, Number of Pages, Page Number.\n",
        "\n",
        "            Document:\n",
        "            {extracted_content}\n",
        "            \"\"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        classification_results[file_name] = f\"Error: {e}\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # or \"gpt-4.0\"\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "\n",
        "# Display results in JSON format\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmsypD4PRUTi",
        "outputId": "880ecea6-10cd-479e-97ea-11dc93bc88a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping .odt file: alg_model_geen_werkgeversgez_dv10311z2ed.odt\n",
            "```json\n",
            "{\n",
            "  \"file_name\": \"financial_document.pdf\",\n",
            "  \"category\": \"Financial Report\",\n",
            "  \"confidence\": \"High\",\n",
            "  \"description\": \"The document is a financial report containing consolidated financial statements, notes, and supplemental details of a corporation, including a report from an independent registered public accounting firm.\",\n",
            "  \"Number_of_Pages\": 57,\n",
            "  \"Page_Number\": null\n",
            "}\n",
            "```\n",
            "\n",
            "Note: Based on the provided document text, there is no mention of \"Financial and Operational Results for the Year Ended December 31, 2023.\" As such, no specific page number can be returned. Additionally, since a complete document is not provided, the number of pages is estimated based on context.\n"
          ]
        }
      ]
    }
  ]
}